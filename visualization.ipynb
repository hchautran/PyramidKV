{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from models.llama.pitomekv import convert\n",
    "from accelerate import Accelerator\n",
    "from const import  (\n",
    "   LLAMA2_7B,\n",
    "   LLAMA3_8B,\n",
    "   # LLAMA3_1_8B,\n",
    "   LLAMA3_2_3B,\n",
    "   LLAMA3_2_1B\n",
    ")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model2prompt = {\n",
    "    \"narrativeqa\": \"You are given a story, which can be either a novel or a movie script, and a question. Answer the question asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nStory: {context}\\n\\nNow, answer the question based on the story asconcisely as you can, using a single phrase if possible. Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"qasper\": \"You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nArticle: {context}\\n\\n Answer the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \\\"unanswerable\\\". If the question is a yes/no question, answer \\\"yes\\\", \\\"no\\\", or \\\"unanswerable\\\". Do not provide any explanation.\\n\\nQuestion: {input}\\n\\nAnswer:\",\n",
    "    \"multifieldqa_en\": \"Read the following text and answer briefly.\\n\\n{context}\\n\\nNow, answer the following question based on the above text, only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"multifieldqa_zh\": \"阅读以下文字并用中文简短回答：\\n\\n{context}\\n\\n现在请基于上面的文章回答下面的问题，只告诉我答案，不要输出任何其他字词。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"hotpotqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"2wikimqa\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"musique\": \"Answer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nThe following are given passages.\\n{context}\\n\\nAnswer the question based on the given passages. Only give me the answer and do not output any other words.\\n\\nQuestion: {input}\\nAnswer:\",\n",
    "    \"dureader\": \"请基于给定的文章回答下述问题。\\n\\n文章：{context}\\n\\n请基于上述文章回答下面的问题。\\n\\n问题：{input}\\n回答：\",\n",
    "    \"gov_report\": \"You are given a report by a government agency. Write a one-page summary of the report.\\n\\nReport:\\n{context}\\n\\nNow, write a one-page summary of the report.\\n\\nSummary:\",\n",
    "    \"qmsum\": \"You are given a meeting transcript and a query containing a question or instruction. Answer the query in one or more sentences.\\n\\nTranscript:\\n{context}\\n\\nNow, answer the query based on the above meeting transcript in one or more sentences.\\n\\nQuery: {input}\\nAnswer:\",\n",
    "    \"multi_news\": \"You are given several news passages. Write a one-page summary of all news. \\n\\nNews:\\n{context}\\n\\nNow, write a one-page summary of all the news.\\n\\nSummary:\",\n",
    "    \"vcsum\": \"下面有一段会议记录，请你阅读后，写一段总结，总结会议的内容。\\n会议记录：\\n{context}\\n\\n会议总结：\",\n",
    "    \"trec\": \"Please determine the type of the question below. Here are some examples of questions.\\n\\n{context}\\n{input}\",\n",
    "    \"triviaqa\": \"Answer the question based on the given passage. Only give me the answer and do not output any other words. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"samsum\": \"Summarize the dialogue into a few short sentences. The following are some examples.\\n\\n{context}\\n\\n{input}\",\n",
    "    \"lsht\": \"请判断给定新闻的类别，下面是一些例子。\\n\\n{context}\\n{input}\",\n",
    "    \"passage_count\": \"There are some paragraphs below sourced from Wikipedia. Some of them may be duplicates. Please carefully read these paragraphs and determine how many unique paragraphs there are after removing duplicates. In other words, how many non-repeating paragraphs are there in total?\\n\\n{context}\\n\\nPlease enter the final count of unique paragraphs after removing duplicates. The output format should only contain the number, such as 1, 2, 3, and so on.\\n\\nThe final answer is: \",\n",
    "    \"passage_retrieval_en\": \"Here are 30 paragraphs from Wikipedia, along with an abstract. Please determine which paragraph the abstract is from.\\n\\n{context}\\n\\nThe following is an abstract.\\n\\n{input}\\n\\nPlease enter the number of the paragraph that the abstract is from. The answer format must be like \\\"Paragraph 1\\\", \\\"Paragraph 2\\\", etc.\\n\\nThe answer is: \",\n",
    "    \"passage_retrieval_zh\": \"以下是若干段落文字，以及其中一个段落的摘要。请确定给定的摘要出自哪一段。\\n\\n{context}\\n\\n下面是一个摘要\\n\\n{input}\\n\\n请输入摘要所属段落的编号。答案格式必须是\\\"段落1\\\"，\\\"段落2\\\"等格式\\n\\n答案是：\",\n",
    "    \"lcc\": \"Please complete the code given below. \\n{context}Next line of code:\\n\",\n",
    "    \"repobench-p\": \"Please complete the code given below. \\n{context}{input}Next line of code:\\n\"\n",
    "}\n",
    "\n",
    "model2maxlen = {\n",
    "   \"llama2\": 3950,\n",
    "   \"llama-2\": 3950,\n",
    "   \"llama3\": 7950,\n",
    "   \"llama-3\": 7950,\n",
    "   \"mistral\": 31500\n",
    "}\n",
    "\n",
    "dataset2maxlen = {\n",
    "    \"narrativeqa\": 128,\n",
    "    \"qasper\": 128,\n",
    "    \"multifieldqa_en\": 64,\n",
    "    \"multifieldqa_zh\": 64,\n",
    "    \"hotpotqa\": 32,\n",
    "    \"2wikimqa\": 32,\n",
    "    \"musique\": 32,\n",
    "    \"dureader\": 128,\n",
    "    \"gov_report\": 512,\n",
    "    \"qmsum\": 512,\n",
    "    \"multi_news\": 512,\n",
    "    \"vcsum\": 512,\n",
    "    \"trec\": 64,\n",
    "    \"triviaqa\": 32,\n",
    "    \"samsum\": 128,\n",
    "    \"lsht\": 64,\n",
    "    \"passage_count\": 32,\n",
    "    \"passage_retrieval_en\": 32,\n",
    "    \"passage_retrieval_zh\": 32,\n",
    "    \"lcc\": 64,\n",
    "    \"repobench-p\": 64\n",
    "}\n",
    "\n",
    "sample_method = \"topk\"\n",
    "max_capacity_prompts=512\n",
    "eval_batch_size = 1\n",
    "max_num_examples=None\n",
    "\n",
    "def build_chat(prompt):\n",
    "        prompt = f\"[INST] {prompt} [/INST]\"\n",
    "        return prompt\n",
    "\n",
    "def read_data(data_file:str, dataset:str, model_path:str):\n",
    "   print(\"Loading data...\")\n",
    "    \n",
    "   test_data = []\n",
    "   \n",
    "   prompts = []\n",
    "   inputs = []\n",
    "   contexts = []\n",
    "   answerss = []\n",
    "   lengths = []\n",
    "   datasets = []\n",
    "   languages = []\n",
    "   all_classess = []\n",
    "   _ids = []\n",
    "   \n",
    "   input_max_len = 0\n",
    "   \n",
    "   for key in model2maxlen:\n",
    "      if key in model_path:\n",
    "         model_max_len = model2maxlen[key]\n",
    "         \n",
    "\n",
    "   output_max_len = dataset2maxlen[dataset]\n",
    "   with open(data_file) as fp:\n",
    "      for line in fp:\n",
    "         example = json.loads(line)\n",
    "         \n",
    "         \n",
    "         length = example[\"length\"]\n",
    "         if length > input_max_len: input_max_len = length\n",
    "         \n",
    "         template = model2prompt[dataset]\n",
    "         prompt = template.format(**example)\n",
    "         \n",
    "         if \"llama2\" in model_path.lower():\n",
    "               prompt = build_chat(prompt)\n",
    "               \n",
    "         example[\"prompt\"] = prompt\n",
    "               \n",
    "         test_data.append(example)\n",
    "      \n",
    "   print(f\"Max Length is {input_max_len}\")\n",
    "      \n",
    "   if max_num_examples and len(test_data) > max_num_examples:\n",
    "      if sample_method == \"random\":\n",
    "         test_data = random.sample(test_data, max_num_examples)\n",
    "      elif sample_method == \"topk\":\n",
    "         test_data = test_data[:max_num_examples]\n",
    "   \n",
    "   batch = {} \n",
    "   for example in test_data:\n",
    "      \n",
    "      prompts.append(example[\"prompt\"])\n",
    "      inputs.append(example[\"input\"])\n",
    "      contexts.append(example[\"context\"])\n",
    "      answerss.append(example[\"answers\"])\n",
    "      lengths.append(example[\"length\"])\n",
    "      datasets.append(example[\"dataset\"])\n",
    "      languages.append(example[\"language\"])\n",
    "      all_classess.append(example[\"all_classes\"])\n",
    "      _ids.append(example[\"_id\"])\n",
    "\n",
    "   print(\"Finish loading model and tokenizer\")\n",
    "   \n",
    "\n",
    "\n",
    "   return prompts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pitome\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "model_checkpoint_path = LLAMA2_7B \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint_path, torch_dtype=torch.float16)\n",
    "accelerator.prepare(model)\n",
    "convert(model)\n",
    "model.config.output_attention = True\n",
    "\n",
    "directory = \"attention\"\n",
    "\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "   os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_energy(metric:torch.Tensor, sigma:float=0.1):\n",
    "   metric = F.normalize(metric, p=2, dim=-1) \n",
    "   sim = metric@metric.transpose(-1,-2)\n",
    "   energy_score = (torch.exp(-(((1 - sim)/sigma)**2 * 0.5))).mean(-1) *  1/(sigma*torch.sqrt(torch.tensor(2*torch.pi)))\n",
    "   return energy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_infer_with_llama_with_attention(prompt, max_length=50):\n",
    "\n",
    "   input_ids = tokenizer.encode(prompt, return_tensors='pt').to(accelerator.device)\n",
    "   print(input_ids.shape)\n",
    "   all_layers_attentions = [] \n",
    "\n",
    "   for _ in range(max_length):\n",
    "\n",
    "      raw_outputs = model(input_ids, output_attentions=True, return_dict=True)\n",
    "      output = raw_outputs.logits\n",
    "      next_token_logits = output[:, -1, :]\n",
    "      \n",
    "      attentions = raw_outputs.attentions\n",
    "\n",
    "      next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "\n",
    "      input_ids = torch.cat([input_ids, next_token.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "      if next_token in tokenizer.all_special_ids:\n",
    "         break\n",
    "      \n",
    "   for i in range(len(attentions)):\n",
    "      all_layers_attentions.append(attentions[i].detach().cpu())\n",
    "   return tokenizer.decode(input_ids[0], skip_special_tokens=True), input_ids[0], all_layers_attentions, raw_outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = [\"multi_news\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "   data = load_dataset('THUDM/LongBench', dataset, split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(lambda x: x[\"length\"] < 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data[1]\n",
    "template = model2prompt[dataset]\n",
    "prompt = template.format(**example)\n",
    "prompt = build_chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2224\n"
     ]
    }
   ],
   "source": [
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 593])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 23.70 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 23.67 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 715.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results, input_ids, all_layers_attentions, past_key_values \u001b[38;5;241m=\u001b[39m \u001b[43mmanual_infer_with_llama_with_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mmanual_infer_with_llama_with_attention\u001b[0;34m(prompt, max_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m all_layers_attentions \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[0;32m----> 9\u001b[0m    raw_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m    output \u001b[38;5;241m=\u001b[39m raw_outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     11\u001b[0m    next_token_logits \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1164\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/PyramidKV/models/llama/pitomekv.py:381\u001b[0m, in \u001b[0;36mPiToMeLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    378\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[0;32m--> 381\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/PyramidKV/models/llama/pitomekv.py:304\u001b[0m, in \u001b[0;36mPiToMeLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    302\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    303\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 304\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    307\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:216\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 23.70 GiB of which 11.88 MiB is free. Including non-PyTorch memory, this process has 23.67 GiB memory in use. Of the allocated memory 21.51 GiB is allocated by PyTorch, and 715.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "results, input_ids, all_layers_attentions, past_key_values = manual_infer_with_llama_with_attention(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "for layer_idx, attentions in enumerate(all_layers_attentions):\n",
    "   attention = attentions * 10000\n",
    "\n",
    "   attention_average = torch.mean(attention, dim=1)\n",
    "\n",
    "   attention_average = attention_average[0]\n",
    "\n",
    "   attention = attention_average\n",
    "\n",
    "   id2token = []\n",
    "   for id in input_ids:\n",
    "      id2token.append(tokenizer.decode(id.item()))\n",
    "\n",
    "   id2token = id2token[0:]\n",
    "   indices = list(range(len(id2token)))\n",
    "\n",
    "\n",
    "\n",
    "   num_heads = 1\n",
    "   sequence_length = 10\n",
    "\n",
    "   # attention = attention.cpu().detach().numpy()a\n",
    "   energy = cal_energy(past_key_values[layer_idx][0], sigma=0.1)\n",
    "   energy_np = energy.mean(1).cpu().detach().numpy()\n",
    "\n",
    "   fig = plt.figure(figsize=(9, 10))\n",
    "   gs = gridspec.GridSpec(9, 10)\n",
    "\n",
    "   ax1 = fig.add_subplot(gs[:-1, :])\n",
    "   ax2 = fig.add_subplot(gs[-1, :], sharex=ax1)\n",
    "\n",
    "   # ax1.imshow(attention, vmax=100)\n",
    "   ax1.imshow(attention, vmax=100)\n",
    "   ax2.imshow(energy_np.reshape(1, -1), cmap='inferno', aspect='auto')\n",
    "   # plt.xticks(ticks=np.arange(len(id2token)), labels=[], rotation=90)\n",
    "   # plt.yticks(ticks=np.arange(len(id2token)), labels=[], rotation=90)\n",
    "   # ax.set_xticks(np.arang (len(id2token)), labels=[])\n",
    "   # ax.set_yticks(np.arange(len(id2token)), labels=[])\n",
    "   plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "   \n",
    "   # ax1.imshow(energy_np, aspect='auto', cmap='viridis')\n",
    "\n",
    "   plt.tight_layout()\n",
    "   plt.savefig(f'attention/layer{layer_idx}.png', dpi=300, format='png')\n",
    "   plt.show()\n",
    "   # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_np.reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between attribute1 and attribute2: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'attribute1': [1, 2, 3, 4, 5],\n",
    "    'attribute2': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df['attribute1'].corr(df['attribute2'])\n",
    "print(f\"Correlation between attribute1 and attribute2: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['attribute1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "Name: attribute1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attribute1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "mask = torch.tril(torch.ones(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y1 = np.array([1, 4, 9, 16, 25])\n",
    "y2 = np.array([2, 3, 5, 7, 11])\n",
    "y3 = np.array([3, 4, 6, 8, 12])\n",
    "\n",
    "# Plotting the lines\n",
    "plt.plot(x, y1, label='Line 1')\n",
    "plt.plot(x, y2, label='Line 2')\n",
    "plt.plot(x, y3, label='Line 3')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Two Lines on the Same Plot')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/caduser/da936c0b-edd7-470e-ab92-9b972b220fe7/chau/miniconda3/envs/pkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from const import LLAMA3_8B\n",
    "from models.llama.pitomekv import convert \n",
    "\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(LLAMA3_8B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pitome\n"
     ]
    }
   ],
   "source": [
    "convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): PiToMeLlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x PiToMeLlamaDecoderLayer(\n",
       "        (self_attn): PiToMeLlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 294/294 [00:00<00:00, 5621.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset('THUDM/LongBench', 'multi_news_e', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongBench(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, args):\n",
    "        print('preparing data...')\n",
    "        self.dataset = load_dataset('THUDM/LongBench', f'{dataset}_e', split='test')\n",
    "        self.test_data = []\n",
    "        self.prompts = []\n",
    "        self.inputs = []\n",
    "        self.contexts = []\n",
    "        self.answers = []\n",
    "        self.lengths = []\n",
    "        self.datasets = []\n",
    "        self.languages = []\n",
    "        self.all_classess = []\n",
    "        self._ids = []\n",
    "        self.input_max_len = 0\n",
    "        self.output_max_len = dataset2maxlen[dataset]\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.length = len(dataset)\n",
    "\n",
    "        for sample in self.dataset:\n",
    "            length = sample[\"length\"]\n",
    "            if length > input_max_len: input_max_len = length\n",
    "            \n",
    "            template = model2prompt[dataset]\n",
    "            prompt = template.format(**sample)\n",
    "            \n",
    "            if \"llama2\" in args.model_path.lower():\n",
    "                prompt = build_chat(prompt)\n",
    "                \n",
    "            sample[\"prompt\"] = prompt\n",
    "            self.test_data.append(sample)\n",
    "        print(f\"Max Length is {input_max_len}\")\n",
    "        if args.max_num_examples and len(test_data) > args.max_num_examples:\n",
    "            if args.sample_method == \"random\":\n",
    "                test_data = random.sample(test_data, args.max_num_examples)\n",
    "            elif args.sample_method == \"topk\":\n",
    "                test_data = test_data[:args.max_num_examples]\n",
    "\n",
    "        for sample in test_data:\n",
    "            self.prompts.append(sample[\"prompt\"])\n",
    "            self.inputs.append(sample[\"input\"])\n",
    "            self.contexts.append(sample[\"context\"])\n",
    "            self.answerss.append(sample[\"answers\"])\n",
    "            self.lengths.append(sample[\"length\"])\n",
    "            self.datasets.append(sample[\"dataset\"])\n",
    "            self.languages.append(sample[\"language\"])\n",
    "            self.all_classess.append(sample[\"all_classes\"])\n",
    "            self._ids.append(sample[\"_id\"])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
